{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting raw data into ingredients fit for our strategy recipe is an annoying yet necessary work. Here's how I cleaned and processed data for this project."
   ]
  },
  {
   "source": [
    "Ultimately, we want these data:\n",
    "\n",
    "1. Industry Index Price Series (Quarterly)\n",
    "2. Industry Index Total Return Series (Quarterly)\n",
    "3. Industry Index Earnings Series (Quarterly)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from xquant.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_div = pd.read_csv('D:/Repositories/cicc/Industry Momentum + CAPE/data/dividends.csv', parse_dates=['announced'], dtype={'ticker':str})\n",
    "df_price = pd.read_csv('D:/Repositories/cicc/Industry Momentum + CAPE/data/price.csv', index_col=['date'], parse_dates=['date'])\n",
    "df_mktcap = pd.read_csv('D:/Repositories/cicc/Industry Momentum + CAPE/data/market_cap.csv', index_col=['date'], parse_dates=['date'])\n",
    "df_comp = pd.read_csv('D:/Repositories/cicc/Industry Momentum + CAPE/data/WIND_index_members.csv', parse_dates=['included', 'excluded'])\n",
    "df_map = pd.read_csv('D:/Repositories/cicc/Industry Momentum + CAPE/data/ticker_map.csv', index_col=['key'])\n",
    "df_idx = pd.read_csv('D:/Repositories/cicc/Industry Momentum + CAPE/data/WIND_industry_index.csv', index_col=['Date'], parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time range for back test\n",
    "START = datetime(2010,1,1)\n",
    "END = datetime(2020,12,31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean dividend data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_div['ticker'] = df_div['ticker'].apply(add_suffix) # convert ticker symbol into standard format (e.g. 000001.SZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_div.dropna(subset=['announced'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Index Members Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map symbols to actual names of industry\n",
    "df_comp['industry'] = df_comp['industry'].apply(lambda x: df_map.at[x,'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if stock is still a member of the index, set excluded time to a future data far away\n",
    "df_comp['excluded'].fillna(pd.Timestamp('20991231'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.dropna(subset=['included'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Financial Metrics for an Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very often we would need to look at certain metrics of an index, such as earnings and dividends. In a market capitalization weighted indices with $n$ members, its metric $m$ is calculated by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sum^{n}_{i=1} w_{i} \\cdot m_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $w$ is the weight of member $i$ in the index (i.e. market cap of member $i$ divided by sum of market cap for all members)."
   ]
  },
  {
   "source": [
    "### First calculate the scale (i.e. multiplier) for each industry index at a certain date"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scale(date) -> dict:\n",
    "    d = dict.fromkeys(df_idx.columns,[])\n",
    "    for i in df_idx.columns:\n",
    "        total = 0\n",
    "        f = get_index_weights(df_mktcap, df_comp.query(f\"industry=='{i}'\"), pd.Timestamp(date))\n",
    "        for s in f.index:\n",
    "            local_sum = f[s] * df_price.at[pd.Timestamp(date), s]\n",
    "            if pd.notna(local_sum):\n",
    "                total += local_sum\n",
    "        if total != 0:            \n",
    "            d[i] = df_idx.at[date,i]/total\n",
    "        else:\n",
    "            d[i] = np.nan\n",
    "    return d"
   ]
  },
  {
   "source": [
    "### Then calculate the quarterly weighted sum of a metric"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_sum(start, end, df, sum_col):\n",
    "    begin = time.time()\n",
    "    days = [closest_trading_day(day, df_price.index, 'bfill') for day in quarter_generator(start,end)]\n",
    "    df_sum = pd.DataFrame(index=days, columns=df_idx.columns)\n",
    "\n",
    "    for day in df_sum.index:\n",
    "        print('\\r', f'Now processing: {day.date()}', end='')\n",
    "        if day.quarter == 1:\n",
    "            look_up = (day.year-1, 4)\n",
    "        else:\n",
    "            look_up = (day.year, day.quarter-1)\n",
    "\n",
    "        scale_dict = get_scale(day)\n",
    "        for industry in df_idx.columns:\n",
    "            w = get_index_weights(df_mktcap, df_comp.query(f\"industry=='{industry}'\"), day)\n",
    "\n",
    "            weighted = {}\n",
    "            multiplier = scale_dict[industry]\n",
    "\n",
    "            for stock in w.index:\n",
    "                s = quarter_sum(ticker=stock, quarter=look_up, df=df, sum_col=sum_col, date_col='announced')\n",
    "                weighted_sum = w[stock] * s\n",
    "                weighted[stock] = weighted_sum\n",
    "\n",
    "            df_sum.at[day, industry] = pd.Series(weighted, dtype=float).sum() * multiplier\n",
    "    \n",
    "    print(f'\\ncomputation completed in {time.time()-begin} seconds.')\n",
    "    return df_sum"
   ]
  },
  {
   "source": [
    "### Quarterly Dividends"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Now processing: 2020-10-09\n",
      "computation completed in 332.9604961872101 seconds.\n"
     ]
    }
   ],
   "source": [
    "df_div_q = get_weighted_sum(START,END, df_div, 'div_per_share')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Energy  Materials Industrials Consumer Discretionary  \\\n",
       "2010-01-04        0          0   0.0218262                      0   \n",
       "2010-04-01        0   0.053968   0.0925406              0.0043455   \n",
       "2010-07-01  13.4659    3.63686      1.1797               0.416404   \n",
       "2010-10-08  7.01905   0.346822    0.686881               0.223824   \n",
       "2011-01-04        0  0.0349391   0.0760834             0.00520137   \n",
       "\n",
       "           Consumer Staples Health Care Financials Information Technology  \\\n",
       "2010-01-04                0           0   0.222113             0.00167726   \n",
       "2010-04-01        0.0128965    0.273544  0.0181898              0.0900128   \n",
       "2010-07-01          4.17079     3.38796    9.37131                1.09074   \n",
       "2010-10-08         0.814055    0.758163    2.91279               0.126117   \n",
       "2011-01-04       0.00242668    0.168036          0                      0   \n",
       "\n",
       "           Communication Services  Utilities Real Estate  \n",
       "2010-01-04                      0          0         NaN  \n",
       "2010-04-01                      0  0.0312638         NaN  \n",
       "2010-07-01                7.03341    1.35964         NaN  \n",
       "2010-10-08                      0    2.06145         NaN  \n",
       "2011-01-04                      0          0         NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Energy</th>\n      <th>Materials</th>\n      <th>Industrials</th>\n      <th>Consumer Discretionary</th>\n      <th>Consumer Staples</th>\n      <th>Health Care</th>\n      <th>Financials</th>\n      <th>Information Technology</th>\n      <th>Communication Services</th>\n      <th>Utilities</th>\n      <th>Real Estate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2010-01-04</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0218262</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.222113</td>\n      <td>0.00167726</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2010-04-01</th>\n      <td>0</td>\n      <td>0.053968</td>\n      <td>0.0925406</td>\n      <td>0.0043455</td>\n      <td>0.0128965</td>\n      <td>0.273544</td>\n      <td>0.0181898</td>\n      <td>0.0900128</td>\n      <td>0</td>\n      <td>0.0312638</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2010-07-01</th>\n      <td>13.4659</td>\n      <td>3.63686</td>\n      <td>1.1797</td>\n      <td>0.416404</td>\n      <td>4.17079</td>\n      <td>3.38796</td>\n      <td>9.37131</td>\n      <td>1.09074</td>\n      <td>7.03341</td>\n      <td>1.35964</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2010-10-08</th>\n      <td>7.01905</td>\n      <td>0.346822</td>\n      <td>0.686881</td>\n      <td>0.223824</td>\n      <td>0.814055</td>\n      <td>0.758163</td>\n      <td>2.91279</td>\n      <td>0.126117</td>\n      <td>0</td>\n      <td>2.06145</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2011-01-04</th>\n      <td>0</td>\n      <td>0.0349391</td>\n      <td>0.0760834</td>\n      <td>0.00520137</td>\n      <td>0.00242668</td>\n      <td>0.168036</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df_div_q.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_div_q.to_csv('\\\\data\\\\quarterly_dividends.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd06e6f7603a0f222095c70729fb7e573f6543910ef3182ccf7976686bfcf8a95e3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}