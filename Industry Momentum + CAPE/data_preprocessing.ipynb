{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting raw data into ingredients fit for our strategy recipe is an annoying yet necessary work. Here's how I cleaned and processed data for this project."
   ]
  },
  {
   "source": [
    "Ultimately, we want these data:\n",
    "\n",
    "1. Industry Index Price Series (Quarterly)\n",
    "2. Industry Index Total Return Series (Quarterly)\n",
    "3. Industry Index Earnings Series (Quarterly)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from xquant.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_div = pd.read_csv('D:/Repositories/cicc/Industry Momentum + CAPE/data/dividends.csv', parse_dates=['announced'], dtype={'ticker':str})\n",
    "df_price = pd.read_csv('D:/Repositories/cicc/Industry Momentum + CAPE/data/price.csv', index_col=['date'], parse_dates=['date'])\n",
    "df_mktcap = pd.read_csv('D:/Repositories/cicc/Industry Momentum + CAPE/data/market_cap.csv', index_col=['date'], parse_dates=['date'])\n",
    "df_comp = pd.read_csv('D:/Repositories/cicc/Industry Momentum + CAPE/data/WIND_index_members.csv', parse_dates=['included', 'excluded'])\n",
    "df_map = pd.read_csv('D:/Repositories/cicc/Industry Momentum + CAPE/data/ticker_map.csv', index_col=['key'])\n",
    "df_idx = pd.read_csv('D:/Repositories/cicc/Industry Momentum + CAPE/data/WIND_industry_index.csv', index_col=['Date'], parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time range for back test\n",
    "START = datetime(2010,1,1)\n",
    "END = datetime(2020,12,31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean dividend data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_div['ticker'] = df_div['ticker'].apply(add_suffix) # convert ticker symbol into standard format (e.g. 000001.SZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_div.dropna(subset=['announced'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Index Members Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map symbols to actual names of industry\n",
    "df_comp['industry'] = df_comp['industry'].apply(lambda x: df_map.at[x,'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if stock is still a member of the index, set excluded time to a future data far away\n",
    "df_comp['excluded'].fillna(pd.Timestamp('20991231'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.dropna(subset=['included'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Financial Metrics for an Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very often we would need to look at certain metrics of an index, such as earnings and dividends. In a market capitalization weighted indices with $n$ members, its metric $m$ is calculated by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sum^{n}_{i=1} w_{i} \\cdot m_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $w$ is the weight of member $i$ in the index (i.e. market cap of member $i$ divided by sum of market cap for all members)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scale(date) -> dict:\n",
    "    d = dict.fromkeys(df_idx.columns,[])\n",
    "    for i in df_idx.columns:\n",
    "        total = 0\n",
    "        f = get_index_weights(df_mktcap, df_comp.query(f\"industry=='{i}'\"), pd.Timestamp(date))\n",
    "        for s in f.index:\n",
    "            local_sum = f[s] * df_price.at[pd.Timestamp(date), s]\n",
    "            if pd.notna(local_sum):\n",
    "                total += local_sum\n",
    "        if total != 0:            \n",
    "            d[i] = df_idx.at[date,i]/total\n",
    "        else:\n",
    "            d[i] = np.nan\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_sum(start, end):\n",
    "    begin = time.time()\n",
    "    days = [closest_trading_day(day, df_price.index, 'bfill') for day in quarter_generator(start,end)]\n",
    "    df_sum = pd.DataFrame(index=days, columns=df_idx.columns)\n",
    "\n",
    "    for day in df_sum.index:\n",
    "        print('\\r', f'Now processing: {day.date()}', end='')\n",
    "        if day.quarter == 1:\n",
    "            look_up = (day.year-1, 4)\n",
    "        else:\n",
    "            look_up = (day.year, x.quarter-1)\n",
    "\n",
    "        scale_dict = get_scale(day)\n",
    "        for industry in df_idx.columns:\n",
    "            w = get_index_weights(df_mktcap, df_comp.query(f\"industry=='{industry}'\"), day)\n",
    "\n",
    "            weighted = {}\n",
    "            multiplier = scale_dict[industry]\n",
    "\n",
    "            for stock in w.index:\n",
    "                s = quarter_sum(ticker=stock, quarter=look_up, df=df_div, sum_col='div_per_share', date_col='announced')\n",
    "                weighted_sum = w[stock] * s\n",
    "                weighted[stock] = weighted_sum\n",
    "\n",
    "            df_sum.at[day, industry] = pd.Series(weighted, dtype=float).sum() * multiplier\n",
    "    \n",
    "    print(f'\\ncomputation completed in {time.time()-begin} seconds.')\n",
    "    return df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Now processing: 2020-10-09computation completed in 350.86790466308594 seconds.\n"
     ]
    }
   ],
   "source": [
    "df_div_q = get_weighted_sum(START,END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_div_q.to_csv('quarterly_dividends.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd06e6f7603a0f222095c70729fb7e573f6543910ef3182ccf7976686bfcf8a95e3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}